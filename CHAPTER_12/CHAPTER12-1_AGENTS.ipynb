{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d124d22-de73-436b-86cd-9b162b469be8",
   "metadata": {
    "id": "2d124d22-de73-436b-86cd-9b162b469be8"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "\n",
    "# Uninstall conflicting packages\n",
    "%pip uninstall -y langchain_classic langchain-core langchain-openai langchain-community langchain langchain-chroma chromadb beautifulsoup4 python-dotenv PyPDF2 rank_bm25 weaviate-client ragas wikipedia langchain-weaviate langchain-together langchain-experimental tiktoken langgraph langchain-tavily\n",
    "\n",
    "# Install compatible versions of langchain-core and langchain-openai\n",
    "%pip install langchain-community==0.4.1\n",
    "%pip install langchain-text-splitters==1.0.0\n",
    "%pip install langchain-openai==1.1.0\n",
    "%pip install langsmith==0.4.49\n",
    "%pip install langchain==1.1.0\n",
    "\n",
    "# Install remaining packages\n",
    "%pip install langchain-chroma==1.0.0\n",
    "%pip install chromadb==1.3.5\n",
    "%pip install python-dotenv==1.2.1\n",
    "%pip install PyPDF2==3.0.1 -q --user\n",
    "%pip install rank_bm25==0.2.2\n",
    "%pip install langchain-classic==1.0.0\n",
    "%pip install langchain_core==1.1.3\n",
    "\n",
    "# new agent-related installs\n",
    "%pip install tiktoken==0.12.0\n",
    "%pip install langgraph==1.0.4\n",
    "%pip install langchain-tavily==0.2.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f884314f-870c-4bfb-b6c1-a5b4801ec172",
   "metadata": {
    "executionInfo": {
     "elapsed": 7390,
     "status": "ok",
     "timestamp": 1715455737041,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "f884314f-870c-4bfb-b6c1-a5b4801ec172"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USER_AGENT'] = 'RAGUserAgent'\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langsmith import Client\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_chroma import Chroma\n",
    "import chromadb\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_classic.retrievers import EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba3468a-d7c2-4a79-8df2-c335542950f2",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1715455737042,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "eba3468a-d7c2-4a79-8df2-c335542950f2"
   },
   "outputs": [],
   "source": [
    "# variables\n",
    "_ = load_dotenv(dotenv_path='env.txt')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0, streaming=True)\n",
    "agent_llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, streaming=True)\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "pdf_path = \"google-2023-environmental-report.pdf\"\n",
    "collection_name = \"google_environmental_report\"\n",
    "str_output_parser = StrOutputParser()\n",
    "user_query = \"What are Google's environmental initiatives?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad428a-3eb6-40ec-a1a5-62565ead1e5b",
   "metadata": {
    "id": "d3ad428a-3eb6-40ec-a1a5-62565ead1e5b"
   },
   "outputs": [],
   "source": [
    "#### INDEXING ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ccda2c-0f4c-41c5-804d-2227cdf35aa7",
   "metadata": {
    "executionInfo": {
     "elapsed": 19512,
     "status": "ok",
     "timestamp": 1715455756551,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "98ccda2c-0f4c-41c5-804d-2227cdf35aa7"
   },
   "outputs": [],
   "source": [
    "# Load the PDF and extract text\n",
    "pdf_reader = PdfReader(pdf_path)\n",
    "text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a4c65-aa05-486c-8295-2f99673e7c20",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1715455756552,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "927a4c65-aa05-486c-8295-2f99673e7c20"
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "splits = character_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e79382-dbb5-4e53-8d21-c4b4375d5084",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_documents = [Document(page_content=text, metadata={\"id\": str(i), \"source\": \"dense\"}) for i, text in enumerate(splits)]\n",
    "sparse_documents = [Document(page_content=text, metadata={\"id\": str(i), \"source\": \"sparse\"}) for i, text in enumerate(splits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b13568c-d633-464d-8c43-0d55f34cc8c1",
   "metadata": {
    "executionInfo": {
     "elapsed": 9471,
     "status": "ok",
     "timestamp": 1715455766015,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "6b13568c-d633-464d-8c43-0d55f34cc8c1"
   },
   "outputs": [],
   "source": [
    "# Chroma Vector Store\n",
    "chroma_client = chromadb.Client()\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=dense_documents,\n",
    "    embedding=embedding_function,\n",
    "    collection_name=collection_name,\n",
    "    client=chroma_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a399c41-0fb0-4a68-a220-88c4ab661e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "sparse_retriever = BM25Retriever.from_documents(sparse_documents, k=10)\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[dense_retriever, sparse_retriever], weights=[0.5, 0.5], c=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfdd5e7-8cfb-4eee-a605-1ecaa5828e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TOOLS ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1783c5-143b-4850-90eb-4a91769661d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool #1: Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b8878-3a43-43f7-ad8e-dab992aff860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tavily Setup\n",
    "# set up your API key at https://tavily.com/\n",
    "# add the API key to your env.txt file\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "_ = load_dotenv(dotenv_path='env.txt')\n",
    "os.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY')\n",
    "web_search = TavilySearch(max_results=4)\n",
    "web_search_name = web_search.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf02c540-c5bb-4af4-bb3d-3629e0ba0075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "web_search.invoke(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d9ab1-7496-42af-92d7-b12370160c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool #2: Data Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb43c44-d394-4ad3-ba83-9270aba9ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    ensemble_retriever,\n",
    "    \"retrieve_google_environmental_question_answers\",\n",
    "    \"Extensive information about Google environmental efforts from 2023.\",\n",
    ")\n",
    "retriever_tool_name = retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f102d1-612d-43fa-b310-af07e748d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools for agent\n",
    "tools = [web_search, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07ad612-b59d-40a1-bbd7-c2fab4aed25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, Sequence, TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1819a56d-b376-4055-be1c-b3fa4441ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.prebuilt import tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0ef771-7a67-4469-915c-58239c3dd9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer \n",
    "    the question. If you don't know the answer, just say \n",
    "    that you don't know. Provide a thorough description to \n",
    "    fully answer the question, utilizing any relevant \n",
    "    information you find.\n",
    "    \n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    \n",
    "    Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbbd119-fc4f-412b-8935-1616a7d847a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edges - determines whether the retrieved documents are relevant to the question.\n",
    "def score_documents(state) -> Literal[\"generate\", \"improve\"]:\n",
    "\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # Data model - returns a binary score for the relevance check\n",
    "    class scoring(BaseModel):\n",
    "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "\n",
    "    # LLM with tool and validation\n",
    "    llm_with_tool = llm.with_structured_output(scoring)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        You are assessing relevance of a retrieved document to a user question with a binary grade. \\n \n",
    "        \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        \n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "        \"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"generate\"\n",
    "\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        print(score)\n",
    "        return \"improve\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadfd63e-c526-4897-a426-9f248fea3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8d2842-590e-441a-bafd-e4f8370c1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent node - invokes the agent model to generate a response based on the current state. \n",
    "# Decision choices (given the question): retrieve using the retriever tool, web_search tool, both, or end.\n",
    "def agent(state):\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    llm = agent_llm.bind_tools(tools)\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]} # Return list, will get added to existing list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b5ea9-16d0-4f1e-b0a9-ecf481c8a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve node - transform the query to produce a better question.\n",
    "def improve(state):\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(content=f\"\"\"\\n \n",
    "            Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "            Here is the initial question:\n",
    "            \\n ------- \\n\n",
    "            {question} \n",
    "            \\n ------- \\n\n",
    "            Formulate an improved question: \n",
    "            \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Scoring\n",
    "    response = llm.invoke(msg)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd3ec6-bc33-464b-a47c-f0054d2688ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate node - generate answer\n",
    "def generate(state):\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    # Chain\n",
    "    rag_chain = generation_prompt | llm | str_output_parser\n",
    "\n",
    "    # Run\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b36d98-a2ac-453e-b97e-db6cd2ce474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclical Graph Setup\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(\"agent\", agent)  # agent\n",
    "retrieve = ToolNode(tools)\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieval from web and or retriever\n",
    "workflow.add_node(\"improve\", improve)  # Improving the question for better retrieval\n",
    "workflow.add_node(\"generate\", generate)  # Generating a response after we know the documents are relevant\n",
    "\n",
    "# Call agent node to decide to retrieve or not\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Decide whether to retrieve (assess agent decision)\n",
    "workflow.add_conditional_edges(\"agent\", tools_condition, \n",
    "    # Translate the condition outputs to nodes in our graph\n",
    "    {\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Edges taken after the `action` node is called (assess agent decision)\n",
    "workflow.add_conditional_edges(\"retrieve\", score_documents)\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"improve\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44402c63-207d-4669-93ad-062abd9685e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca0689-04c2-45e4-abbf-bf29f96647ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", user_query),\n",
    "    ]\n",
    "}\n",
    "final_answer = ''\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "        final_answer = value\n",
    "    pprint.pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ebf7a-ccd5-4946-8daf-985f8cd6736f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_answer['messages'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da5c40-fdbc-458f-800f-4089d01b4030",
   "metadata": {},
   "source": [
    "*Formatted:*\n",
    "\n",
    "Google has a comprehensive and multifaceted approach to environmental sustainability, encompassing various initiatives aimed at reducing carbon emissions, promoting sustainable practices, and leveraging technology for environmental benefits. Here are some key aspects of Google's environmental initiatives:\n",
    "\n",
    "1. **Carbon Reduction and Renewable Energy**:  \n",
    "- **iMasons Climate Accord**: Google is a founding member and part of the governing body of this coalition focused on reducing carbon emissions in digital infrastructure.\n",
    "- **Net-Zero Carbon**: Google is committed to operating sustainably with a focus on achieving net-zero carbon emissions. This includes investments in carbon-free energy and energy-efficient facilities, such as their all-electric, net water-positive Bay View campus.\n",
    "\n",
    "2. **Sustainable Consumption and Circular Economy**:\n",
    "- **Right to Repair**: Google has engaged with the European Commission to promote the repair and reuse of goods, particularly smartphones and tablets.\n",
    "- **Circular Economy**: Google works with suppliers to ensure environmental criteria are met, including the management of hazardous substances and resource efficiency. They also promote recycling and the use of refurbished products.\n",
    "\n",
    "3. **Water Stewardship**:\n",
    "- Google supports watershed projects and responsible water use, including initiatives in Chile and the United States. Their Bay View campus incorporates stormwater retention and other water-positive features.\n",
    "\n",
    "4. **Food Waste Reduction**:\n",
    "- **ReFED**: Google provided anchor funding to the ReFED Catalytic Grant Fund to accelerate and scale food waste solutions.\n",
    "\n",
    "5. **Reforestation and Biodiversity**:\n",
    "- **The Nature Conservancy (TNC)**: Google supports reforestation projects and the development of technology to stop deforestation in the Amazon. They also work on kelp reforestation and other biodiversity initiatives.\n",
    "\n",
    "6. **Technology and Data for Environmental Action**:\n",
    "- **Google Earth Engine**: Provides access to data for monitoring environmental changes.\n",
    "- **Environmental Insights Explorer**: Helps cities and organizations measure and reduce their carbon footprint.\n",
    "- **Google Maps Eco-Friendly Routing**: Offers routes that reduce carbon emissions, helping users make more sustainable travel choices.\n",
    "\n",
    "7. **Public Policy and Advocacy**:\n",
    "- Google engages in public policy advocacy to support clean energy and climate action, including comments on the U.S. Department of Energy's Clean Hydrogen Production Standard and participation in the First Movers Coalition for carbon dioxide removal.\n",
    "\n",
    "8. **Partnerships and Coalitions**:\n",
    "- Google collaborates with various organizations, including the World Business Council for Sustainable Development (WBCSD) and the World Resources Institute (WRI), to promote sustainability and address climate change.\n",
    "\n",
    "9. **Empowering Individuals and Communities**:\n",
    "- Google aims to help 1 billion people make more sustainable choices through their products by 2030. This includes features like energy-efficient Google Nest thermostats and carbon emissions information in Google Flights.\n",
    "\n",
    "Overall, Google's environmental initiatives are extensive and integrated into their business operations, product development, and community engagement, reflecting their commitment to sustainability and climate action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7419cb3-32ed-4f19-8a2a-e27155f9a628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CHAPTER8-2_HYBRID-ENSEMBLE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
