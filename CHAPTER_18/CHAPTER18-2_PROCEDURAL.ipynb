{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00bc02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE-STEP: Install Required Dependencies\n",
    "%pip install langchain\n",
    "%pip install langgraph\n",
    "%pip install langchain-openai\n",
    "%pip install chromadb\n",
    "%pip install python-dotenv\n",
    "%pip install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60903289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE-STEP: Import Core Libraries and Configure Environment\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, TypedDict, Annotated, Sequence\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Initialize environment and models\n",
    "load_dotenv(dotenv_path='env.txt')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# State and memory structures\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    working_memory: dict\n",
    "    episodic_recall: list\n",
    "    semantic_facts: dict\n",
    "    user_id: str\n",
    "    conversation_id: str\n",
    "\n",
    "class SemanticFact(BaseModel):\n",
    "    subject: str = Field(description=\"Entity or topic\")\n",
    "    predicate: str = Field(description=\"Relationship or property\")\n",
    "    object: str = Field(description=\"Value or related entity\")\n",
    "    confidence: float = Field(description=\"Confidence score 0-1\")\n",
    "    source: str = Field(description=\"Source: user or assistant\")\n",
    "\n",
    "# Initialize vector store\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"agent_memory\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./memory_store\"\n",
    ")\n",
    "\n",
    "# Episodic memory functions\n",
    "def store_episodic_memory(vector_store, conversation_id: str, messages: List, summary: str = None):\n",
    "    if not summary and messages:\n",
    "        summary = f\"Conversation about: {messages[0][1] if isinstance(messages[0], tuple) else messages[0].content[:100]}...\"\n",
    "    metadata = {\n",
    "        \"type\": \"episodic\",\n",
    "        \"conversation_id\": conversation_id,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"message_count\": len(messages)\n",
    "    }\n",
    "    conversation_text = \"\"\n",
    "    for msg in messages:\n",
    "        conversation_text += f\"{msg[0]}: {msg[1]}\\n\" if isinstance(msg, tuple) else f\"{msg.type}: {msg.content}\\n\"\n",
    "    vector_store.add_documents([Document(page_content=conversation_text, metadata=metadata)])\n",
    "    return conversation_id\n",
    "\n",
    "def retrieve_episodic_memories(vector_store, query: str, k: int = 3):\n",
    "    return vector_store.similarity_search(query=query, k=k, filter={\"type\": {\"$eq\": \"episodic\"}})\n",
    "\n",
    "# Semantic memory functions\n",
    "def extract_semantic_facts(messages: List) -> List[SemanticFact]:\n",
    "    extraction_prompt = PromptTemplate.from_template(\"\"\"\n",
    "    Analyze this conversation and extract important factual statements.\n",
    "    Conversation: {conversation}\n",
    "    Extract facts in JSON format:\n",
    "    {{\"facts\": [{{\"subject\": \"...\", \"predicate\": \"...\", \"object\": \"...\", \n",
    "                  \"confidence\": 0.0-1.0, \"source\": \"user or assistant\"}}]}}\n",
    "    Only extract clear facts. Output valid JSON only.\n",
    "    \"\"\")\n",
    "    conversation_text = \"\"\n",
    "    for msg in messages:\n",
    "        conversation_text += f\"{msg[0]}: {msg[1]}\\n\" if isinstance(msg, tuple) else f\"{msg.type}: {msg.content}\\n\"\n",
    "    try:\n",
    "        result = (extraction_prompt | llm | JsonOutputParser()).invoke({\"conversation\": conversation_text})\n",
    "        return [SemanticFact(**fact_dict) for fact_dict in result.get(\"facts\", [])]\n",
    "    except Exception as e:\n",
    "        print(f\"Fact extraction error: {e}\")\n",
    "        return []\n",
    "\n",
    "def store_semantic_facts(vector_store, facts: List[SemanticFact], user_id: str = \"default\"):\n",
    "    documents = []\n",
    "    for fact in facts:\n",
    "        documents.append(Document(\n",
    "            page_content=f\"{fact.subject} {fact.predicate} {fact.object}\",\n",
    "            metadata={\n",
    "                \"type\": \"semantic\", \"user_id\": user_id,\n",
    "                \"subject\": fact.subject, \"predicate\": fact.predicate,\n",
    "                \"object\": fact.object, \"confidence\": fact.confidence,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        ))\n",
    "    if documents:\n",
    "        vector_store.add_documents(documents)\n",
    "    return len(documents)\n",
    "\n",
    "def retrieve_semantic_facts(vector_store, query: str, user_id: str = \"default\", k: int = 5):\n",
    "    results = vector_store.similarity_search(\n",
    "        query=query, k=k,\n",
    "        filter={\"$and\": [{\"type\": {\"$eq\": \"semantic\"}}, {\"user_id\": {\"$eq\": user_id}}]}\n",
    "    )\n",
    "    return [{\n",
    "        \"subject\": doc.metadata.get(\"subject\"),\n",
    "        \"predicate\": doc.metadata.get(\"predicate\"),\n",
    "        \"object\": doc.metadata.get(\"object\"),\n",
    "        \"confidence\": doc.metadata.get(\"confidence\", 1.0)\n",
    "    } for doc in results]\n",
    "\n",
    "def format_semantic_context(facts: List[Dict]) -> str:\n",
    "    if not facts:\n",
    "        return \"No relevant facts found.\"\n",
    "    context = \"Known facts:\\n\"\n",
    "    for fact in facts:\n",
    "        if fact.get('confidence', 1.0) > 0.7:\n",
    "            context += f\"- {fact['subject']} {fact['predicate']} {fact['object']}\\n\"\n",
    "    return context\n",
    "\n",
    "# Unified memory agent\n",
    "def unified_memory_agent(state: AgentState) -> dict:\n",
    "    current_messages = state.get(\"messages\", [])\n",
    "    user_id = state.get(\"user_id\", \"default\")\n",
    "    conversation_id = state.get(\"conversation_id\", f\"conv_{datetime.now().timestamp()}\")\n",
    "    \n",
    "    episodic_context = \"\"\n",
    "    semantic_context = \"\"\n",
    "    \n",
    "    if current_messages:\n",
    "        latest_query = current_messages[-1][1] if isinstance(current_messages[-1], tuple) else current_messages[-1].content\n",
    "        \n",
    "        # Retrieve memories\n",
    "        past_episodes = retrieve_episodic_memories(vector_store, latest_query, k=2)\n",
    "        if past_episodes:\n",
    "            episodic_context = \"Relevant past conversations:\\n\"\n",
    "            for episode in past_episodes:\n",
    "                timestamp = episode.metadata.get('timestamp', 'Unknown')\n",
    "                episodic_context += f\"[{timestamp}]:\\n{episode.page_content[:200]}...\\n\\n\"\n",
    "        \n",
    "        facts = retrieve_semantic_facts(vector_store, latest_query, user_id=user_id, k=3)\n",
    "        semantic_context = format_semantic_context(facts)\n",
    "    \n",
    "    # Generate response with memory context\n",
    "    memory_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an AI assistant with both episodic and semantic memory.\n",
    "{semantic_context}\n",
    "{episodic_context}\n",
    "Current conversation:\n",
    "{messages}\n",
    "Respond using your memories when relevant. Be consistent with known facts and past conversations.\n",
    "\"\"\")\n",
    "    \n",
    "    formatted_messages = \"\"\n",
    "    for msg in current_messages[-5:] if current_messages else []:\n",
    "        formatted_messages += f\"{msg[0]}: {msg[1]}\\n\" if isinstance(msg, tuple) else f\"{msg.type}: {msg.content}\\n\"\n",
    "    \n",
    "    response = (memory_prompt | llm | output_parser).invoke({\n",
    "        \"semantic_context\": semantic_context,\n",
    "        \"episodic_context\": episodic_context,\n",
    "        \"messages\": formatted_messages\n",
    "    })\n",
    "    \n",
    "    # Store memories\n",
    "    if len(current_messages) >= 2:\n",
    "        store_episodic_memory(vector_store, conversation_id, current_messages)\n",
    "    \n",
    "    if current_messages:\n",
    "        messages_with_response = current_messages + [(\"assistant\", response)]\n",
    "        new_facts = extract_semantic_facts(messages_with_response[-3:])\n",
    "        if new_facts:\n",
    "            stored = store_semantic_facts(vector_store, new_facts, user_id)\n",
    "            state[\"semantic_facts\"] = {\"extracted\": stored}\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [(\"assistant\", response)],\n",
    "        \"episodic_recall\": past_episodes if past_episodes else [],\n",
    "        \"semantic_facts\": state.get(\"semantic_facts\", {})\n",
    "    }\n",
    "\n",
    "# Build and compile workflow\n",
    "memory_workflow = StateGraph(AgentState)\n",
    "memory_workflow.add_node(\"memory_agent\", unified_memory_agent)\n",
    "memory_workflow.set_entry_point(\"memory_agent\")\n",
    "memory_workflow.add_edge(\"memory_agent\", END)\n",
    "memory_app = memory_workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9a69a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1:\n",
      "Hi Sarah! It's great to meet you. As a data scientist working on climate models, you must have a fascinating job. If you have any specific questions or topics you'd like to discuss, feel free to ask!\n",
      "\n",
      "==================================================\n",
      "\n",
      "Response 2 (with semantic memory):\n",
      "For time series forecasting, the choice of machine learning techniques can depend on the nature of your data and the patterns you want to capture. Here are some recommendations based on known facts:\n",
      "\n",
      "1. **XGBoost/LightGBM**: These gradient boosting methods are effective, especially when you engineer time-based features such as lags and rolling statistics. They can handle non-linear relationships well and are often used in competitions for their performance.\n",
      "\n",
      "2. **ARIMA/SARIMA**: If your data exhibits linear patterns and seasonality, traditional statistical models like ARIMA or SARIMA can be very effective. They are particularly useful for datasets where the underlying relationships are more linear.\n",
      "\n",
      "3. **LSTM (Long Short-Term Memory) or TCN (Temporal Convolutional Networks)**: These deep learning models are particularly useful for capturing complex temporal dependencies in environmental data. They can model long-range dependencies and are suitable for datasets with intricate patterns.\n",
      "\n",
      "Depending on your specific use case, you might want to experiment with a combination of these methods to see which yields the best results for your forecasting needs.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Response 3 (with episodic and semantic memory):\n",
      "For your team meeting, I recommend considering some delicious and easy-to-eat options like Caprese Sandwiches. They are fresh, satisfying, and perfect for a meeting setting. \n",
      "\n",
      "Additionally, Mediterranean Mezze Platters would be a great choice as they are flavorful, great for sharing, and offer plenty of vegetarian-friendly options. If your team enjoys sushi, Vegetable Sushi Rolls could also be a nice addition.\n",
      "\n",
      "If you need help finding local restaurants or catering services that specialize in these options, just let me know your location, and I can provide some recommendations!\n"
     ]
    }
   ],
   "source": [
    "# PRE-STEP: Establish facts\n",
    "test_1 = {\n",
    "    \"messages\": [(\"user\", \"Hi, I'm Sarah Chen. I'm a data scientist working on climate models. I'm vegetarian and prefer concise technical explanations.\")],\n",
    "    \"user_id\": \"sarah_chen\",\n",
    "    \"conversation_id\": \"conv_001\"\n",
    "}\n",
    "\n",
    "result_1 = memory_app.invoke(test_1)\n",
    "print(\"Response 1:\")\n",
    "print(result_1[\"messages\"][-1][1] if isinstance(result_1[\"messages\"][-1], tuple) else result_1[\"messages\"][-1].content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test 2: Use semantic memory\n",
    "test_2 = {\n",
    "    \"messages\": [(\"user\", \"What machine learning techniques would you recommend for time series forecasting?\")],\n",
    "    \"user_id\": \"sarah_chen\",\n",
    "    \"conversation_id\": \"conv_002\"\n",
    "}\n",
    "\n",
    "result_2 = memory_app.invoke(test_2)\n",
    "print(\"Response 2 (with semantic memory):\")\n",
    "print(result_2[\"messages\"][-1][1] if isinstance(result_2[\"messages\"][-1], tuple) else result_2[\"messages\"][-1].content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test 3: Reference past conversation and facts\n",
    "test_3 = {\n",
    "    \"messages\": [(\"user\", \"Can you recommend some lunch options for our team meeting?\")],\n",
    "    \"user_id\": \"sarah_chen\",\n",
    "    \"conversation_id\": \"conv_003\"\n",
    "}\n",
    "\n",
    "result_3 = memory_app.invoke(test_3)\n",
    "print(\"Response 3 (with full memory context):\")\n",
    "print(result_3[\"messages\"][-1][1] if isinstance(result_3[\"messages\"][-1], tuple) else result_3[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf68d7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install LangMem and Additional Dependencies\n",
    "%pip install -q langgraph-checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd13de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import Components and Create Memory Infrastructure\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import hashlib\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b138498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create Custom Memory Management Tools\n",
    "class SimpleMemoryStore:\n",
    "    \"\"\"Lightweight memory store for demonstration\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.memories = {}\n",
    "        self.memory_index = []\n",
    "        \n",
    "    def add_memory(self, content: str, user_id: str = \"default\", metadata: dict = None):\n",
    "        \"\"\"Add a memory to the store\"\"\"\n",
    "        memory_id = hashlib.md5(f\"{content}{datetime.now().isoformat()}\".encode()).hexdigest()[:8]\n",
    "        memory_entry = {\n",
    "            \"id\": memory_id,\n",
    "            \"content\": content,\n",
    "            \"user_id\": user_id,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"metadata\": metadata or {}\n",
    "        }\n",
    "        self.memories[memory_id] = memory_entry\n",
    "        self.memory_index.append((memory_id, content))\n",
    "        return memory_id\n",
    "    \n",
    "    def search_memories(self, query: str, user_id: str = \"default\", k: int = 3):\n",
    "        \"\"\"Simple keyword-based memory search\"\"\"\n",
    "        results = []\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        for memory_id, content in self.memory_index:\n",
    "            memory = self.memories.get(memory_id)\n",
    "            if memory and memory[\"user_id\"] == user_id:\n",
    "                # Simple relevance scoring based on keyword overlap\n",
    "                score = sum(1 for word in query_lower.split() if word in content.lower())\n",
    "                if score > 0:\n",
    "                    results.append((score, memory))\n",
    "        \n",
    "        # Sort by relevance and return top k\n",
    "        results.sort(key=lambda x: x[0], reverse=True)\n",
    "        return [memory for _, memory in results[:k]]\n",
    "\n",
    "# Create memory store instance\n",
    "memory_store = SimpleMemoryStore()\n",
    "\n",
    "# Create tool functions that mimic LangMem's interface\n",
    "def manage_memory_tool(memories: list, user_id: str = \"default\"):\n",
    "    \"\"\"Tool to store memories\"\"\"\n",
    "    stored_ids = []\n",
    "    for memory in memories:\n",
    "        if isinstance(memory, dict):\n",
    "            content = memory.get(\"content\", str(memory))\n",
    "            metadata = memory.get(\"metadata\", {})\n",
    "        else:\n",
    "            content = str(memory)\n",
    "            metadata = {}\n",
    "        \n",
    "        memory_id = memory_store.add_memory(content, user_id, metadata)\n",
    "        stored_ids.append(memory_id)\n",
    "    \n",
    "    return {\"stored\": len(stored_ids), \"ids\": stored_ids}\n",
    "\n",
    "def search_memory_tool(query: str, user_id: str = \"default\"):\n",
    "    \"\"\"Tool to search memories\"\"\"\n",
    "    results = memory_store.search_memories(query, user_id)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce4118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create Procedural Memory Manager\n",
    "class ProceduralMemoryManager:\n",
    "    \"\"\"Manages procedural memory and prompt optimization\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.performance_log = deque(maxlen=100)  # Keep last 100 interactions\n",
    "        self.current_rules = []\n",
    "        self.rule_performance = {}  # Track rule effectiveness\n",
    "        \n",
    "    def log_interaction(self, query: str, response: str, success: bool, feedback: str = None):\n",
    "        \"\"\"Log interaction for procedural learning\"\"\"\n",
    "        entry = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"query\": query,\n",
    "            \"response\": response[:200],\n",
    "            \"success\": success,\n",
    "            \"feedback\": feedback,\n",
    "            \"active_rules\": [r[\"condition\"] for r in self.current_rules[:3]]\n",
    "        }\n",
    "        self.performance_log.append(entry)\n",
    "        \n",
    "        # Update rule performance metrics\n",
    "        for rule_condition in entry[\"active_rules\"]:\n",
    "            if rule_condition not in self.rule_performance:\n",
    "                self.rule_performance[rule_condition] = {\"success\": 0, \"total\": 0}\n",
    "            self.rule_performance[rule_condition][\"total\"] += 1\n",
    "            if success:\n",
    "                self.rule_performance[rule_condition][\"success\"] += 1\n",
    "        \n",
    "        # Trigger rule extraction after every 5 interactions\n",
    "        if len(self.performance_log) % 5 == 0:\n",
    "            self.extract_procedural_rules()\n",
    "    \n",
    "    def extract_procedural_rules(self):\n",
    "        \"\"\"Analyze logs to extract behavioral improvements\"\"\"\n",
    "        if len(self.performance_log) < 3:\n",
    "            return\n",
    "        \n",
    "        recent_logs = list(self.performance_log)[-10:]\n",
    "        successful = [log for log in recent_logs if log[\"success\"]]\n",
    "        failed = [log for log in recent_logs if not log[\"success\"]]\n",
    "        \n",
    "        extraction_prompt = PromptTemplate.from_template(\"\"\"\n",
    "        Analyze these interaction logs and extract procedural rules to improve behavior.\n",
    "        \n",
    "        Successful interactions ({success_count}):\n",
    "        {successful_examples}\n",
    "        \n",
    "        Failed interactions ({fail_count}):\n",
    "        {failed_examples}\n",
    "        \n",
    "        Extract 1-3 specific behavioral rules in this format:\n",
    "        {{\"rules\": [\n",
    "            {{\"condition\": \"If user asks for explanation\", \n",
    "              \"action\": \"Then provide structured response with examples\", \n",
    "              \"priority\": 1-10}}\n",
    "        ]}}\n",
    "        \n",
    "        Focus on clear, actionable patterns.\n",
    "        Output valid JSON only.\n",
    "        \"\"\")\n",
    "        \n",
    "        try:\n",
    "            result = (extraction_prompt | llm | JsonOutputParser()).invoke({\n",
    "                \"success_count\": len(successful),\n",
    "                \"successful_examples\": \"\\n\".join([f\"- Query: {s['query']}\" for s in successful[:3]]),\n",
    "                \"fail_count\": len(failed),\n",
    "                \"failed_examples\": \"\\n\".join([f\"- Query: {f['query']}\" for f in failed[:3]])\n",
    "            })\n",
    "            \n",
    "            new_rules = result.get(\"rules\", [])\n",
    "            if new_rules:\n",
    "                # Add performance tracking for new rules\n",
    "                for rule in new_rules:\n",
    "                    rule[\"performance\"] = {\"success\": 0, \"total\": 0}\n",
    "                \n",
    "                self.current_rules.extend(new_rules)\n",
    "                # Keep only highest priority, best performing rules\n",
    "                self.current_rules = sorted(\n",
    "                    self.current_rules, \n",
    "                    key=lambda x: (x.get(\"priority\", 0), self._get_rule_success_rate(x)),\n",
    "                    reverse=True\n",
    "                )[:5]\n",
    "                \n",
    "                print(f\"✓ Extracted {len(new_rules)} new procedural rules\")\n",
    "        except Exception as e:\n",
    "            print(f\"Rule extraction error: {e}\")\n",
    "    \n",
    "    def _get_rule_success_rate(self, rule):\n",
    "        \"\"\"Calculate success rate for a rule\"\"\"\n",
    "        perf = self.rule_performance.get(rule[\"condition\"], {\"success\": 0, \"total\": 1})\n",
    "        return perf[\"success\"] / max(perf[\"total\"], 1)\n",
    "    \n",
    "    def get_active_rules(self) -> str:\n",
    "        \"\"\"Format current rules for prompt injection\"\"\"\n",
    "        if not self.current_rules:\n",
    "            return \"\"\n",
    "        \n",
    "        rules_text = \"PROCEDURAL RULES (learned from experience):\\n\"\n",
    "        for i, rule in enumerate(self.current_rules[:3], 1):  # Use top 3 rules\n",
    "            success_rate = self._get_rule_success_rate(rule)\n",
    "            rules_text += f\"{i}. {rule['condition']} → {rule['action']} (success: {success_rate:.0%})\\n\"\n",
    "        return rules_text\n",
    "\n",
    "# Initialize procedural manager\n",
    "procedural_manager = ProceduralMemoryManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ad28842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SStep 5: Create Memory-Enhanced Agent with Procedural Learning\n",
    "def procedural_agent(state: AgentState) -> dict:\n",
    "    \"\"\"Agent with procedural memory and hot-path memory tools\"\"\"\n",
    "    \n",
    "    current_messages = state.get(\"messages\", [])\n",
    "    user_id = state.get(\"user_id\", \"default\")\n",
    "    \n",
    "    if not current_messages:\n",
    "        return {\"messages\": [(\"assistant\", \"Hello! How can I help you today?\")]}\n",
    "    \n",
    "    # Get latest query\n",
    "    latest_query = current_messages[-1][1] if isinstance(current_messages[-1], tuple) else current_messages[-1].content\n",
    "    \n",
    "    # Search relevant memories (hot-path)\n",
    "    memory_results = search_memory_tool(latest_query, user_id)\n",
    "    memory_context = \"\"\n",
    "    if memory_results:\n",
    "        memory_context = \"Relevant memories:\\n\"\n",
    "        for mem in memory_results[:2]:\n",
    "            memory_context += f\"- {mem['content'][:100]}...\\n\"\n",
    "    \n",
    "    # Get active procedural rules\n",
    "    procedural_rules = procedural_manager.get_active_rules()\n",
    "    \n",
    "    # Create enhanced prompt with procedural memory\n",
    "    enhanced_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an adaptive AI assistant that learns from experience.\n",
    "\n",
    "{procedural_rules}\n",
    "\n",
    "{memory_context}\n",
    "\n",
    "Current conversation:\n",
    "{messages}\n",
    "\n",
    "Important: Follow the procedural rules above to optimize your response.\n",
    "Response:\"\"\")\n",
    "    \n",
    "    # Format messages\n",
    "    formatted_messages = \"\"\n",
    "    for msg in current_messages[-5:] if current_messages else []:\n",
    "        formatted_messages += f\"{msg[0]}: {msg[1]}\\n\" if isinstance(msg, tuple) else f\"{msg.type}: {msg.content}\\n\"\n",
    "    \n",
    "    # Generate response\n",
    "    response = (enhanced_prompt | llm | output_parser).invoke({\n",
    "        \"procedural_rules\": procedural_rules,\n",
    "        \"memory_context\": memory_context,\n",
    "        \"messages\": formatted_messages\n",
    "    })\n",
    "    \n",
    "    # Store interaction in memory (hot-path)\n",
    "    memory_entry = {\n",
    "        \"content\": f\"Q: {latest_query}\\nA: {response[:200]}\",\n",
    "        \"metadata\": {\"type\": \"interaction\", \"timestamp\": datetime.now().isoformat()}\n",
    "    }\n",
    "    manage_memory_tool([memory_entry], user_id)\n",
    "    \n",
    "    # Log for procedural learning\n",
    "    # Simulate success based on response quality indicators\n",
    "    success = (\n",
    "        len(response) > 50 and \n",
    "        len(response) < 500 and \n",
    "        not response.endswith(\"?\") and\n",
    "        (\"example\" in response.lower() or \"step\" in response.lower() or len(response.split('\\n')) > 2)\n",
    "    )\n",
    "    \n",
    "    procedural_manager.log_interaction(latest_query, response, success)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [(\"assistant\", response)],\n",
    "        \"working_memory\": {\"memory_stored\": True, \"success\": success}\n",
    "    }\n",
    "\n",
    "# Create workflow\n",
    "procedural_workflow = StateGraph(AgentState)\n",
    "procedural_workflow.add_node(\"procedural_agent\", procedural_agent)\n",
    "procedural_workflow.set_entry_point(\"procedural_agent\")\n",
    "procedural_workflow.add_edge(\"procedural_agent\", END)\n",
    "\n",
    "procedural_app = procedural_workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbd31010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Background Memory Optimization\n",
    "def optimize_memories_background():\n",
    "    \"\"\"Background task to optimize memories and extract patterns\"\"\"\n",
    "    \n",
    "    print(\"\\n🔄 Running background memory optimization...\")\n",
    "    \n",
    "    # Extract and refine procedural rules\n",
    "    procedural_manager.extract_procedural_rules()\n",
    "    \n",
    "    # Display performance metrics\n",
    "    if procedural_manager.current_rules:\n",
    "        print(f\"📊 Active procedural rules: {len(procedural_manager.current_rules)}\")\n",
    "        for i, rule in enumerate(procedural_manager.current_rules[:3], 1):\n",
    "            success_rate = procedural_manager._get_rule_success_rate(rule)\n",
    "            print(f\"   {i}. {rule['condition'][:50]}...\")\n",
    "            print(f\"      → {rule['action'][:50]}...\")\n",
    "            print(f\"      Performance: {success_rate:.0%}\")\n",
    "    \n",
    "    # Memory consolidation (simulate)\n",
    "    print(f\"💾 Total memories stored: {len(memory_store.memories)}\")\n",
    "    \n",
    "    return {\"status\": \"optimization_complete\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84a7e701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Testing Procedural Memory System\n",
      "\n",
      "Response 1 (no procedural rules):\n",
      "Quantum computing is a type of computation that leverages the principles of quantum mechanics to process information in fundamentally different ways than classical computers. Here are some key concept\n",
      "...\n",
      "\n",
      "============================================================\n",
      "\n",
      "📚 Training phase - simulating multiple interactions...\n",
      "\n",
      "• Query: What's machine learning?... Success: False\n",
      "• Query: Hello... Success: False\n",
      "• Query: Explain neural networks... Success: False\n",
      "✓ Extracted 3 new procedural rules\n",
      "• Query: What time is it?... Success: False\n",
      "• Query: How does encryption work?... Success: False\n",
      "• Query: Thanks... Success: False\n",
      "\n",
      "🔄 Running background memory optimization...\n",
      "✓ Extracted 3 new procedural rules\n",
      "📊 Active procedural rules: 5\n",
      "   1. If user asks about a technical topic like machine ...\n",
      "      → Then break down the concept into simple terms and ...\n",
      "      Performance: 0%\n",
      "   2. If user asks about a technical topic...\n",
      "      → Then break down the topic into simpler terms and p...\n",
      "      Performance: 0%\n",
      "   3. If user asks for explanation...\n",
      "      → Then provide structured response with examples...\n",
      "      Performance: 0%\n",
      "💾 Total memories stored: 7\n",
      "\n",
      "============================================================\n",
      "\n",
      "Response 2 (with procedural rules):\n",
      "Blockchain technology is a system for recording information in a way that makes it difficult or impossible to change, hack, or cheat the system. Here’s a breakdown of the concept in simpler terms:\n",
      "\n",
      "### What is Blockchain?\n",
      "1. **Structure**: Imagine a digital ledger or record book that is shared across many computers. Each page in this book is called a \"block,\" and each block contains a list of transactions.\n",
      "2. **Chain**: These blocks are linked together in chronological order, forming a \"chain.\" This is where the term \"blockchain\" comes from.\n",
      "3. **Decentralization**: Instead of being stored in one central location, the blockchain is distributed across a network of computers (nodes). This means that everyone in the network has access to the same information, making it transparent.\n",
      "\n",
      "### Key Features:\n",
      "- **Immutability**: Once a block is added to the chain, it cannot be altered without changing all subsequent blocks, which requires consensus from the network. This makes the data secure and trustworthy.\n",
      "- **Transparency**: All transactions are visible to everyone on the network, which helps prevent fraud.\n",
      "- **Consensus Mechanisms**: To add a new block, the network must agree on its validity through various methods (like Proof of Work or Proof of Stake).\n",
      "\n",
      "### Applications of Blockchain:\n",
      "1. **Cryptocurrencies**: The most well-known application is Bitcoin, which uses blockchain to enable peer-to-peer transactions without a central authority.\n",
      "2. **Supply Chain Management**: Companies can track products from origin to consumer, ensuring transparency and reducing fraud.\n",
      "3. **Smart Contracts**: These are self-executing contracts with the terms directly written into code, allowing for automated and trustless transactions.\n",
      "4. **Voting Systems**: Blockchain can be used to create secure and transparent voting systems, reducing the risk of tampering.\n",
      "\n",
      "In summary, blockchain technology is a secure and transparent way to record transactions and data, with applications ranging from finance to supply chain management.\n",
      "\n",
      "============================================================\n",
      "\n",
      "Response 3 (memory recall):\n",
      "In our previous discussions, we have touched on the topic of machine learning. Here’s a brief overview of what we covered:\n",
      "\n",
      "1. **Definition**: Machine learning is a subset of artificial intelligence that focuses on the development of algorithms that allow computers to learn from and make predictions based on data.\n",
      "\n",
      "2. **Applications**: We discussed various applications of machine learning, such as:\n",
      "   - **Image Recognition**: Used in facial recognition systems.\n",
      "   - **Natural Language Processing**: Powers virtual assistants and chatbots.\n",
      "   - **Recommendation Systems**: Used by platforms like Netflix and Amazon to suggest content or products.\n",
      "\n",
      "If you have any specific technical topics in mind that you would like to explore further, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Test Procedural Memory System\n",
    "print(\"🚀 Testing Procedural Memory System\\n\")\n",
    "\n",
    "# Test 1: Initial interaction (no rules yet)\n",
    "test_1 = {\n",
    "    \"messages\": [(\"user\", \"Explain quantum computing\")],\n",
    "    \"user_id\": \"demo_user\"\n",
    "}\n",
    "\n",
    "result_1 = procedural_app.invoke(test_1)\n",
    "print(\"Response 1 (no procedural rules):\")\n",
    "print(result_1[\"messages\"][-1][1][:200] if isinstance(result_1[\"messages\"][-1], tuple) else result_1[\"messages\"][-1].content[:200])\n",
    "print(\"...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Simulate training interactions\n",
    "print(\"📚 Training phase - simulating multiple interactions...\\n\")\n",
    "\n",
    "training_data = [\n",
    "    (\"What's machine learning?\", True),  # Good explanation expected\n",
    "    (\"Hello\", False),  # Too simple\n",
    "    (\"Explain neural networks\", True),  # Good explanation expected\n",
    "    (\"What time is it?\", False),  # Can't answer\n",
    "    (\"How does encryption work?\", True),  # Good explanation expected\n",
    "    (\"Thanks\", False),  # Too simple\n",
    "]\n",
    "\n",
    "for query, expected_success in training_data:\n",
    "    test = {\"messages\": [(\"user\", query)], \"user_id\": \"demo_user\"}\n",
    "    result = procedural_app.invoke(test)\n",
    "    print(f\"• Query: {query[:30]}... Success: {result['working_memory']['success']}\")\n",
    "\n",
    "# Run background optimization\n",
    "optimize_memories_background()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Test 2: After learning\n",
    "test_2 = {\n",
    "    \"messages\": [(\"user\", \"Tell me about blockchain technology\")],\n",
    "    \"user_id\": \"demo_user\"\n",
    "}\n",
    "\n",
    "result_2 = procedural_app.invoke(test_2)\n",
    "print(\"Response 2 (with procedural rules):\")\n",
    "print(result_2[\"messages\"][-1][1] if isinstance(result_2[\"messages\"][-1], tuple) else result_2[\"messages\"][-1].content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Test 3: Memory recall\n",
    "test_3 = {\n",
    "    \"messages\": [(\"user\", \"What technical topics have we discussed?\")],\n",
    "    \"user_id\": \"demo_user\"\n",
    "}\n",
    "\n",
    "result_3 = procedural_app.invoke(test_3)\n",
    "print(\"Response 3 (memory recall):\")\n",
    "print(result_3[\"messages\"][-1][1] if isinstance(result_3[\"messages\"][-1], tuple) else result_3[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
