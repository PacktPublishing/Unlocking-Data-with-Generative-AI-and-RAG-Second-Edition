{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00bc02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE-STEP: Install Required Dependencies\n",
    "%pip install langchain\n",
    "%pip install langgraph\n",
    "%pip install langchain-openai\n",
    "%pip install chromadb\n",
    "%pip install python-dotenv\n",
    "%pip install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd56f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you want to run from a clean slate\n",
    "# This clears ALL generated data and memory stores\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "print(\"üßπ Starting complete cleanup...\")\n",
    "\n",
    "# 1. Clear the domain memory store (vector database)\n",
    "if os.path.exists(\"./domain_investment/domain_memory_store\"):\n",
    "    shutil.rmtree(\"./domain_investment/domain_memory_store\")\n",
    "    print(\"  ‚úì Cleared domain memory store\")\n",
    "\n",
    "# 2. Clear the old memory stores from testing (if they exist)\n",
    "test_dirs = [\n",
    "    \"./baseline_memory_store\",  # From Cell 1\n",
    "    \"./full_memory_store\",       # Old name from earlier versions\n",
    "    \"./investment_memory_store\"  # Another old name\n",
    "]\n",
    "for dir_path in test_dirs:\n",
    "    if os.path.exists(dir_path):\n",
    "        shutil.rmtree(dir_path)\n",
    "        print(f\"  ‚úì Cleared {dir_path}\")\n",
    "\n",
    "# 3. Clear generated data (optional - comment out if you want to keep the data)\n",
    "if os.path.exists(\"./domain_investment/investment_advisor_data\"):\n",
    "    # Only clear the generated files, not the directory itself\n",
    "    data_files = [\n",
    "        \"./domain_investment/investment_advisor_data/conversations.jsonl\",\n",
    "        \"./domain_investment/investment_advisor_data/extracted_patterns.json\",\n",
    "        \"./domain_investment/investment_advisor_data/test_scenarios.json\",\n",
    "        \"./domain_investment/investment_advisor_data/statistics.json\"\n",
    "    ]\n",
    "    for file_path in data_files:\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "    print(\"  ‚úì Cleared generated data files\")\n",
    "\n",
    "# 4. Clear any Chroma persistence files in the root directory\n",
    "chroma_files = [\n",
    "    \"chroma.sqlite3\",\n",
    "    \".chroma\"\n",
    "]\n",
    "for file_path in chroma_files:\n",
    "    if os.path.exists(file_path):\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        else:\n",
    "            shutil.rmtree(file_path)\n",
    "        print(f\"  ‚úì Cleared {file_path}\")\n",
    "\n",
    "print(\"\\n‚úÖ Cleanup complete!\")\n",
    "print(\"   You can now restart from Cell 6 with a completely fresh system\")\n",
    "print(\"\\n   Note: The code files (.py) are preserved - only runtime data was cleared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b646f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Initialize the Full CoALA Agent with All Memory Types\n",
    "\"\"\"\n",
    "This cell sets up a complete agent with:\n",
    "- Episodic Memory: Stores past conversations\n",
    "- Semantic Memory: Extracts and stores facts\n",
    "- Procedural Memory: Learns strategies and patterns\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# Import the complete CoALA system\n",
    "from coala_agent import CoALAAgent\n",
    "from domain_investment.investment_advisor_agent import InvestmentAdvisorAgent\n",
    "from domain_investment.investment_advisor_data import EnhancedInvestmentAdvisorDataGenerator\n",
    "from domain_investment.investor_test_scenarios import (\n",
    "    process_baseline_conversations, test_agent_with_queries, \n",
    "    process_performance_feedback, process_remaining_conversations,\n",
    "    test_hierarchical_retrieval, get_key_achievements\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='env.txt')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Create a FRESH agent for testing\n",
    "print(\"üöÄ Initializing Full CoALA Agent with All Memory Types\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create domain agent which encapsulates investment-specific logic\n",
    "domain_agent = InvestmentAdvisorAgent()\n",
    "\n",
    "# Set up memory storage directory\n",
    "domain_memory_dir = os.path.join(domain_agent.domain_dir, \"domain_memory_store\")\n",
    "os.makedirs(domain_memory_dir, exist_ok=True)\n",
    "\n",
    "# Create the full agent with all memory systems\n",
    "full_agent = CoALAAgent(\n",
    "    domain_agent=domain_agent,\n",
    "    model_name=\"gpt-4.1-mini\",\n",
    "    temperature=0.0,\n",
    "    persist_directory=domain_memory_dir,\n",
    "    optimization_algorithm=\"prompt_memory\"  # Can be \"gradient\" or \"metaprompt\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Full CoALA agent initialized with:\")\n",
    "print(f\"  ‚Ä¢ Domain: {full_agent.domain_agent.__class__.__name__}\")\n",
    "print(f\"  ‚Ä¢ Memory Store: {domain_memory_dir}\")\n",
    "\n",
    "# Verify initial state\n",
    "initial_stats = full_agent.get_memory_stats()\n",
    "print(f\"\\nüìä Initial state:\")\n",
    "print(f\"  Episodic/Semantic docs: {initial_stats.get('episodic_semantic', {}).get('total_documents', 0)}\")\n",
    "print(f\"  Procedural strategies: {initial_stats.get('procedural', {}).get('total_strategies', 0)}\")\n",
    "\n",
    "# Test with a simple query\n",
    "test_response = full_agent.process_message(\n",
    "    \"I'm thinking about rebalancing my portfolio. I'm 35 with moderate risk tolerance.\",\n",
    "    user_id=\"test_client_001\"\n",
    ")\n",
    "print(f\"\\nüß™ Test Response: {test_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a32a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load or Generate Synthetic Investment Advisor Data\n",
    "\"\"\"\n",
    "This cell loads realistic conversation data that simulates various types of\n",
    "investment advisory interactions, including both successful and failed conversations.\n",
    "\"\"\"\n",
    "\n",
    "# Get data directory from domain agent\n",
    "data_dir = domain_agent.data_dir\n",
    "conversations_file = os.path.join(data_dir, \"conversations.jsonl\")\n",
    "\n",
    "if os.path.exists(conversations_file):\n",
    "    # Load existing data\n",
    "    print(f\"üìÇ Loading existing conversation data from {data_dir}...\")\n",
    "    conversations = []\n",
    "    with open(conversations_file, 'r') as f:\n",
    "        for line in f:\n",
    "            conversations.append(json.loads(line))\n",
    "else:\n",
    "    # Generate new data\n",
    "    print(f\"üî® Generating new conversation data...\")\n",
    "    generator = EnhancedInvestmentAdvisorDataGenerator(seed=42)\n",
    "    data = generator.export_realistic_data()\n",
    "    conversations = data['conversations']\n",
    "    \n",
    "    # Convert to dict format\n",
    "    conversations = [\n",
    "        conv if isinstance(conv, dict) else conv.__dict__ \n",
    "        for conv in conversations\n",
    "    ]\n",
    "\n",
    "# TESTING:\n",
    "print(f\"‚úÖ Loaded {len(conversations)} conversations\")\n",
    "print(f\"üë• Unique users: {len(set(c['user_id'] for c in conversations))}\")\n",
    "\n",
    "# Display data statistics\n",
    "success_rate = sum(1 for c in conversations if c['feedback']['success']) / len(conversations)\n",
    "avg_satisfaction = sum(c['feedback']['satisfaction_score'] for c in conversations) / len(conversations)\n",
    "\n",
    "print(f\"\\nüìä Data Overview:\")\n",
    "print(f\"  Data location: {data_dir}\")\n",
    "print(f\"  Total conversations: {len(conversations)}\")\n",
    "print(f\"  Unique users: {len(set(c['user_id'] for c in conversations))}\")\n",
    "print(f\"  Success rate: {sum(1 for c in conversations if c['feedback']['success']) / len(conversations):.1%}\")\n",
    "print(f\"  Avg satisfaction: {sum(c['feedback']['satisfaction_score'] for c in conversations) / len(conversations):.1f}/5.0\")\n",
    "\n",
    "# Examine a sample conversation\n",
    "sample_conv = conversations[0]\n",
    "print(f\"\\nüîç Sample Conversation:\")\n",
    "print(f\"  User {sample_conv['user_id']}: {sample_conv['messages'][0]['content']}\")\n",
    "print(f\"  Assistant: {sample_conv['messages'][1]['content']}\")\n",
    "print(f\"  Success: {sample_conv['feedback']['success']}\")\n",
    "print(f\"  Satisfaction: {sample_conv['feedback']['satisfaction_score']}/5.0\")\n",
    "print(f\"  Behavioral signals: {sum(sample_conv['behavioral_signals'].values())} active\")\n",
    "\n",
    "print(f\"\\n‚úÖ Data ready for processing by full agent\\n  Will be stored in: {domain_agent.memory_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c1e201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Process Baseline Conversations to Establish Initial Learning\n",
    "\"\"\"\n",
    "This cell processes the first batch of conversations to establish baseline memories\n",
    "and learning patterns across all three memory systems.\n",
    "\"\"\"\n",
    "print(f\"üìö Processing baseline conversations...\")\n",
    "results = process_baseline_conversations(full_agent, conversations, num_baseline=30)\n",
    "print(f\"\\n‚úÖ Baseline processing complete\")\n",
    "print(f\"  Episodic memories stored: {results['baseline_count']}\")\n",
    "print(f\"  Semantic facts extracted: {results['facts_extracted']} (errors: {results['extraction_errors']})\")\n",
    "learning = results['learning_summary']\n",
    "processed = results['processed']\n",
    "print(f\"  Global strategies: {learning.get('global', 0)}\")\n",
    "print(f\"  User strategies: {learning.get('user', 0)} (for {processed.get('users', 0)} users)\")\n",
    "print(f\"  Community strategies: {learning.get('community', 0)} (for {processed.get('communities', 0)} communities)\")\n",
    "print(f\"  Task strategies: {learning.get('task', 0)} (for {processed.get('tasks', 0)} task types)\")\n",
    "print(\"\\nüë• Community Membership:\")\n",
    "for community_id, members in full_agent.procedural_memory.community_members.items():\n",
    "    if members:\n",
    "        print(f\"  {community_id}: {len(members)} members\")\n",
    "final_stats = full_agent.procedural_memory.get_stats()\n",
    "print(f\"\\nüìä Procedural Memory Statistics:\")\n",
    "print(f\"  Total strategies: {final_stats['total_strategies']}\")\n",
    "print(f\"  By scope: {final_stats['by_scope']}\")\n",
    "print(f\"  Avg success rate: {final_stats['avg_success_rate']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21445b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Test Performance and Trigger Adaptations\n",
    "\"\"\"\n",
    "This cell demonstrates how the agent uses its learned strategies and adapts\n",
    "based on performance feedback, showing continuous improvement.\n",
    "\"\"\"\n",
    "print(\"üß™ Testing agent with learned strategies...\")\n",
    "\n",
    "# Test with different query types\n",
    "test_results = test_agent_with_queries(full_agent)\n",
    "\n",
    "for result in test_results:\n",
    "    print(f\"\\n‚ùì {result['query']}\")\n",
    "    print(f\"üí¨ {result['response']}\")\n",
    "    if result['strategy']:\n",
    "        print(f\"   ‚Üí Using: {result['strategy']['source']} ({result['strategy']['confidence']:.0%})\")\n",
    "\n",
    "# Trigger performance adaptations\n",
    "print(\"\\nüìä Processing performance feedback...\")\n",
    "\n",
    "adaptations, adaptation_details = process_performance_feedback(\n",
    "    full_agent, conversations, start_idx=30, end_idx=40\n",
    ")\n",
    "\n",
    "for detail in adaptation_details:\n",
    "    print(f\"  ‚úì {detail['strategy']} ‚Üí {detail['new_rate']:.0%}\")\n",
    "\n",
    "print(f\"\\n‚úÖ {adaptations} strategies adapted\")\n",
    "\n",
    "# Show final memory stats\n",
    "final_stats = full_agent.get_memory_stats()\n",
    "print(\"\\nüìö Final Memory State:\")\n",
    "print(f\"  Episodic/Semantic: {final_stats['episodic_semantic'].get('total_documents', 0)} documents\")\n",
    "print(f\"  Procedural: {final_stats['procedural'].get('total_strategies', 0)} strategies\")\n",
    "print(f\"  Data location: {full_agent.domain_agent.data_dir}\")\n",
    "print(f\"  Memory location: {full_agent.domain_agent.memory_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea43512",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 5: Complete Learning Progression and Hierarchical Retrieval\n",
    "\"\"\"\n",
    "This final cell demonstrates the complete learning progression and shows how\n",
    "the agent uses hierarchical retrieval to provide personalized responses.\n",
    "\"\"\"\n",
    "print(\"üìä COMPLETE LEARNING PROGRESSION ANALYSIS\")\n",
    "print(f\"\\nüîÑ Processing additional conversations...\")\n",
    "num_processed, learned = process_remaining_conversations(full_agent, conversations, 50, 100)\n",
    "print(f\"\\n‚úÖ Learning complete ({num_processed} conversations processed):\")\n",
    "for scope, count in learned.items():\n",
    "    if count:\n",
    "        print(f\"  {scope.capitalize()}: {count} new strategies\")\n",
    "final_stats = full_agent.procedural_memory.get_stats()\n",
    "print(f\"\\nüìà FINAL PROCEDURAL MEMORY STATISTICS:\")\n",
    "print(f\"  Total strategies learned: {final_stats['total_strategies']}\")\n",
    "print(f\"  Breakdown by scope:\")\n",
    "for scope, count in final_stats['by_scope'].items():\n",
    "    print(f\"    {scope.capitalize()}: {count}\")\n",
    "print(f\"  Average success rate: {final_stats['avg_success_rate']}\")\n",
    "print(f\"  Total adaptations: {final_stats['total_adaptations']}\")\n",
    "print(f\"  Segments discovered: {', '.join(final_stats['segments'])}\")\n",
    "print(\"üî¨ DEMONSTRATING FULL MEMORY INTEGRATION\")\n",
    "query = \"I'm worried about market volatility. Should I move to safer investments?\"\n",
    "test_results = test_hierarchical_retrieval(full_agent, query)\n",
    "for result in test_results:\n",
    "    print(f\"\\nüë§ {result['description']}\\n   User ID: {result['user_id']}\")\n",
    "    if result['strategy']:\n",
    "        print(f\"   Strategy source: {result['strategy']['source']}\")\n",
    "        print(f\"   Scope: {result['strategy']['scope']}\")\n",
    "        print(f\"   Confidence: {result['strategy']['confidence']:.1%}\")\n",
    "print(\"\\nüìä STRATEGY PERFORMANCE BY SCOPE:\")\n",
    "full_agent.procedural_memory.show_strategy_performance()\n",
    "print(\"üéØ KEY ACHIEVEMENTS DEMONSTRATED:\")\n",
    "for achievement in get_key_achievements():\n",
    "    print(f\"‚úì {achievement}\")\n",
    "memory_stats = full_agent.get_memory_stats()\n",
    "memory_stats = full_agent.get_all_memory_stats()\n",
    "print(f\"\\nüìä COMPLETE MEMORY SYSTEM STATISTICS:\")\n",
    "print(f\"  Episodic/Semantic documents: {memory_stats['episodic_semantic'].get('total_documents', 'N/A')}\")\n",
    "print(f\"  Procedural strategies: {memory_stats['procedural']['total_strategies']}\")\n",
    "print(f\"  Optimization algorithm: {memory_stats['procedural']['algorithm']}\")\n",
    "print(f\"  Total optimizations: {memory_stats['procedural']['total_optimizations']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
